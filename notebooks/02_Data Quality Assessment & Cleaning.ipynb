{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7949c7-0685-4d5d-b550-74c16e43ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChainEats Data Quality Assessment\n",
      "==================================================\n",
      "Loading datasets...\n",
      "All datasets loaded successfully!\n",
      "\n",
      "DATASET OVERVIEW\n",
      "------------------------------\n",
      "\n",
      "Locations:\n",
      "  Rows: 50\n",
      "  Columns: 7\n",
      "  Memory: 0.0 MB\n",
      "\n",
      "Menu Items:\n",
      "  Rows: 20\n",
      "  Columns: 6\n",
      "  Memory: 0.0 MB\n",
      "\n",
      "Sales:\n",
      "  Rows: 13,605,203\n",
      "  Columns: 11\n",
      "  Memory: 3692.0 MB\n",
      "\n",
      "Weather:\n",
      "  Rows: 3,650\n",
      "  Columns: 5\n",
      "  Memory: 0.3 MB\n",
      "\n",
      "MISSING VALUES ANALYSIS\n",
      "------------------------------\n",
      "\n",
      "Locations: No missing values\n",
      "\n",
      "Menu Items: No missing values\n",
      "\n",
      "Sales: No missing values\n",
      "\n",
      "Weather: No missing values\n",
      "\n",
      "DATA QUALITY ISSUES\n",
      "------------------------------\n",
      "\n",
      "1. LOCATIONS ANALYSIS:\n",
      "  Cities: 5\n",
      "  Location types: 5\n",
      "  Rent range: $3,098 - $12,795\n",
      "\n",
      "2. MENU ANALYSIS:\n",
      "  Total items: 20\n",
      "  Categories: 5\n",
      "\n",
      "3. SALES ANALYSIS:\n",
      "  Date range: 2022-01-01 00:00:00 to 2023-12-31 00:00:00\n",
      "  Total transactions: 13,605,203\n",
      "  Unique locations: 50\n",
      "  0 transactions with quantity > 5\n",
      "  0 transactions with revenue > $100\n",
      "\n",
      "4. WEATHER ANALYSIS:\n",
      "  Temperature range: 20.0°F to 100.0°F\n",
      "  Rainy days: 730 (20.0%)\n",
      "\n",
      "BUSINESS LOGIC VALIDATION\n",
      "------------------------------\n",
      "All sales locations exist in master data\n",
      "All sales items exist in menu data\n",
      "\n",
      "QUICK BUSINESS INSIGHTS\n",
      "------------------------------\n",
      "\n",
      "Top 5 locations by revenue:\n",
      "  LOC_024 (New York): $12,168,750\n",
      "  LOC_048 (Houston): $11,734,495\n",
      "  LOC_044 (Chicago): $9,509,641\n",
      "  LOC_039 (Los Angeles): $9,078,118\n",
      "  LOC_019 (New York): $9,035,044\n",
      "\n",
      "Category performance:\n",
      "  Pizza: $63,741,381\n",
      "  Burgers: $46,720,711\n",
      "  Salads: $46,680,452\n",
      "  Desserts: $28,305,748\n",
      "  Beverages: $14,707,866\n",
      "\n",
      "Best month: 12 ($20,164,097)\n",
      "Worst month: 2 ($14,000,732)\n",
      "\n",
      "Data exploration complete!\n",
      "Summary: Our data is mostly clean with minor issues to address.\n"
     ]
    }
   ],
   "source": [
    "# ChainEats Analytics - Day 2: Data Exploration & Quality Assessment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"ChainEats Data Quality Assessment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load all datasets\n",
    "print(\"Loading datasets...\")\n",
    "locations_df = pd.read_csv('locations.csv')\n",
    "menu_df = pd.read_csv('menu_items.csv')\n",
    "sales_df = pd.read_csv('sales_data.csv')\n",
    "weather_df = pd.read_csv('weather_data.csv')\n",
    "\n",
    "# Convert date columns\n",
    "sales_df['date'] = pd.to_datetime(sales_df['date'])\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "locations_df['opening_date'] = pd.to_datetime(locations_df['opening_date'])\n",
    "\n",
    "print(\"All datasets loaded successfully!\")\n",
    "\n",
    "# STEP 1: Dataset Overview\n",
    "print(\"\\nDATASET OVERVIEW\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "datasets = {\n",
    "    'Locations': locations_df,\n",
    "    'Menu Items': menu_df, \n",
    "    'Sales': sales_df,\n",
    "    'Weather': weather_df\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Rows: {len(df):,}\")\n",
    "    print(f\"  Columns: {len(df.columns)}\")\n",
    "    print(f\"  Memory: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# STEP 2: Missing Values Check\n",
    "print(\"\\nMISSING VALUES ANALYSIS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"\\n{name} - Missing values:\")\n",
    "        for col, count in missing[missing > 0].items():\n",
    "            print(f\"  {col}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n{name}: No missing values\")\n",
    "\n",
    "# STEP 3: Data Quality Issues Detection\n",
    "print(\"\\nDATA QUALITY ISSUES\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Check locations data\n",
    "print(\"\\n1. LOCATIONS ANALYSIS:\")\n",
    "print(f\"  Cities: {locations_df['city'].nunique()}\")\n",
    "print(f\"  Location types: {locations_df['location_type'].nunique()}\")\n",
    "print(f\"  Rent range: ${locations_df['monthly_rent'].min():,.0f} - ${locations_df['monthly_rent'].max():,.0f}\")\n",
    "\n",
    "# Check for unrealistic rent values\n",
    "problematic_rent = locations_df[(locations_df['monthly_rent'] < 1000) | (locations_df['monthly_rent'] > 15000)]\n",
    "if len(problematic_rent) > 0:\n",
    "    print(f\"  {len(problematic_rent)} locations with unrealistic rent\")\n",
    "\n",
    "# Check menu data\n",
    "print(\"\\n2. MENU ANALYSIS:\")\n",
    "print(f\"  Total items: {len(menu_df)}\")\n",
    "print(f\"  Categories: {menu_df['category'].nunique()}\")\n",
    "\n",
    "# Check for negative margins\n",
    "negative_margin = menu_df[menu_df['profit_margin'] <= 0]\n",
    "if len(negative_margin) > 0:\n",
    "    print(f\"  {len(negative_margin)} items with negative/zero profit margin\")\n",
    "    print(\"  Items:\", negative_margin['item_name'].tolist())\n",
    "\n",
    "# Check sales data\n",
    "print(\"\\n3. SALES ANALYSIS:\")\n",
    "print(f\"  Date range: {sales_df['date'].min()} to {sales_df['date'].max()}\")\n",
    "print(f\"  Total transactions: {len(sales_df):,}\")\n",
    "print(f\"  Unique locations: {sales_df['location_id'].nunique()}\")\n",
    "\n",
    "# Check for unusual quantities or prices\n",
    "unusual_qty = sales_df[sales_df['quantity'] > 5]\n",
    "print(f\"  {len(unusual_qty)} transactions with quantity > 5\")\n",
    "\n",
    "unusual_revenue = sales_df[sales_df['revenue'] > 100]\n",
    "print(f\"  {len(unusual_revenue)} transactions with revenue > $100\")\n",
    "\n",
    "# Check weather data\n",
    "print(\"\\n4. WEATHER ANALYSIS:\")\n",
    "print(f\"  Temperature range: {weather_df['temperature'].min():.1f}°F to {weather_df['temperature'].max():.1f}°F\")\n",
    "print(f\"  Rainy days: {weather_df['is_rainy'].sum():,} ({weather_df['is_rainy'].mean()*100:.1f}%)\")\n",
    "\n",
    "# STEP 4: Business Logic Validation\n",
    "print(\"\\nBUSINESS LOGIC VALIDATION\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Check if all sales locations exist in locations table\n",
    "sales_locations = set(sales_df['location_id'].unique())\n",
    "master_locations = set(locations_df['location_id'].unique())\n",
    "missing_locations = sales_locations - master_locations\n",
    "if missing_locations:\n",
    "    print(f\"{len(missing_locations)} sales locations not in master data\")\n",
    "else:\n",
    "    print(\"All sales locations exist in master data\")\n",
    "\n",
    "# Check if all sales items exist in menu\n",
    "sales_items = set(sales_df['item_id'].unique()) \n",
    "menu_items = set(menu_df['item_id'].unique())\n",
    "missing_items = sales_items - menu_items\n",
    "if missing_items:\n",
    "    print(f\"{len(missing_items)} sales items not in menu data\")\n",
    "else:\n",
    "    print(\"All sales items exist in menu data\")\n",
    "\n",
    "# STEP 5: Quick Business Insights\n",
    "print(\"\\nQUICK BUSINESS INSIGHTS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Top performing locations\n",
    "location_performance = sales_df.groupby('location_id')['revenue'].sum().sort_values(ascending=False)\n",
    "print(\"\\nTop 5 locations by revenue:\")\n",
    "for loc, revenue in location_performance.head().items():\n",
    "    city = locations_df[locations_df['location_id'] == loc]['city'].iloc[0]\n",
    "    print(f\"  {loc} ({city}): ${revenue:,.0f}\")\n",
    "\n",
    "# Category performance\n",
    "category_performance = sales_df.groupby('category')['revenue'].sum().sort_values(ascending=False)\n",
    "print(\"\\nCategory performance:\")\n",
    "for cat, revenue in category_performance.items():\n",
    "    print(f\"  {cat}: ${revenue:,.0f}\")\n",
    "\n",
    "# Monthly trends\n",
    "sales_df['month'] = sales_df['date'].dt.month\n",
    "monthly_sales = sales_df.groupby('month')['revenue'].sum()\n",
    "best_month = monthly_sales.idxmax()\n",
    "worst_month = monthly_sales.idxmin()\n",
    "print(f\"\\nBest month: {best_month} (${monthly_sales[best_month]:,.0f})\")\n",
    "print(f\"Worst month: {worst_month} (${monthly_sales[worst_month]:,.0f})\")\n",
    "\n",
    "print(\"\\nData exploration complete!\")\n",
    "print(\"Summary: Our data is mostly clean with minor issues to address.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "552021a4-8f2f-42b1-832a-79955bf4a065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChainEats Data Cleaning Pipeline\n",
      "==================================================\n",
      "Original data loaded\n",
      "\n",
      "STEP 1: Fixing Menu Items\n",
      "------------------------------\n",
      "Found 0 items with poor margins\n",
      "All menu items now have positive margins\n",
      "\n",
      "STEP 2: Cleaning Sales Data\n",
      "------------------------------\n",
      "Removing 0 transactions with quantity > 5\n",
      "Capping 0 transactions above $50\n",
      "Sales records: 13,605,203 → 13,605,203\n",
      "\n",
      "STEP 3: Adding Business Columns\n",
      "------------------------------\n",
      "Added time features and location details to sales data\n",
      "\n",
      "STEP 4: Creating Summary Tables\n",
      "------------------------------\n",
      "Created daily summary: 36,500 records\n",
      "Created monthly summary: 1,200 records\n",
      "\n",
      "STEP 5: Enhancing Weather Data\n",
      "------------------------------\n",
      "Added temperature categories and weather impact scores\n",
      "\n",
      "STEP 6: Saving Cleaned Data\n",
      "------------------------------\n",
      "All cleaned datasets saved!\n",
      "\n",
      "FINAL DATA QUALITY REPORT\n",
      "==================================================\n",
      "Locations: 50 restaurants across 5 cities\n",
      "Menu: 20 items, all with positive margins\n",
      "Sales: 13,605,203 clean transactions\n",
      "Weather: 3,650 daily records with business impact scores\n",
      "Daily Summary: 36,500 location-day combinations\n",
      "Monthly Summary: 1,200 location-month combinations\n",
      "\n",
      "Data Quality Metrics:\n",
      "  Missing values: 0%\n",
      "  Date range: 2022-01-01 to 2023-12-31\n",
      "  Revenue range: $2.63 - $32.81\n",
      "  All business relationships maintained\n",
      "Data is clean and ready for SQL analysis.\n"
     ]
    }
   ],
   "source": [
    "# ChainEats Analytics - Day 2: Data Cleaning Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"ChainEats Data Cleaning Pipeline\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load datasets\n",
    "locations_df = pd.read_csv('locations.csv')\n",
    "menu_df = pd.read_csv('menu_items.csv')\n",
    "sales_df = pd.read_csv('sales_data.csv')\n",
    "weather_df = pd.read_csv('weather_data.csv')\n",
    "\n",
    "# Convert dates\n",
    "sales_df['date'] = pd.to_datetime(sales_df['date'])\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "locations_df['opening_date'] = pd.to_datetime(locations_df['opening_date'])\n",
    "\n",
    "print(\"Original data loaded\")\n",
    "\n",
    "# CLEANING STEP 1: Fix Menu Items with Negative Margins\n",
    "print(\"\\nSTEP 1: Fixing Menu Items\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Find items with negative or zero margins\n",
    "problematic_items = menu_df[menu_df['profit_margin'] <= 0].copy()\n",
    "print(f\"Found {len(problematic_items)} items with poor margins\")\n",
    "\n",
    "# Fix by adjusting cost to maintain 20% minimum margin\n",
    "for idx, item in problematic_items.iterrows():\n",
    "    old_cost = menu_df.at[idx, 'cost']\n",
    "    new_cost = menu_df.at[idx, 'price'] * 0.8  # 20% margin\n",
    "    menu_df.at[idx, 'cost'] = new_cost\n",
    "    menu_df.at[idx, 'profit_margin'] = menu_df.at[idx, 'price'] - new_cost\n",
    "    print(f\"  {item['item_name']}: Cost ${old_cost:.2f} → ${new_cost:.2f}\")\n",
    "\n",
    "print(\"All menu items now have positive margins\")\n",
    "\n",
    "# CLEANING STEP 2: Handle Unusual Sales Transactions\n",
    "print(\"\\nSTEP 2: Cleaning Sales Data\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "original_sales_count = len(sales_df)\n",
    "\n",
    "# Remove transactions with unrealistic quantities (>5 items same product)\n",
    "unusual_qty = sales_df[sales_df['quantity'] > 5]\n",
    "print(f\"Removing {len(unusual_qty)} transactions with quantity > 5\")\n",
    "sales_df = sales_df[sales_df['quantity'] <= 5]\n",
    "\n",
    "# Cap individual transaction revenue at $50 (reasonable for fast food)\n",
    "high_revenue = sales_df[sales_df['revenue'] > 50]\n",
    "print(f\"Capping {len(high_revenue)} transactions above $50\")\n",
    "sales_df.loc[sales_df['revenue'] > 50, 'quantity'] = 1\n",
    "sales_df.loc[sales_df['revenue'] > 50, 'revenue'] = sales_df.loc[sales_df['revenue'] > 50, 'price']\n",
    "\n",
    "# Recalculate revenue and profit after cleaning\n",
    "sales_df['revenue'] = sales_df['quantity'] * sales_df['price']\n",
    "sales_df['total_cost'] = sales_df['quantity'] * sales_df['cost']\n",
    "sales_df['profit'] = sales_df['revenue'] - sales_df['total_cost']\n",
    "\n",
    "print(f\"Sales records: {original_sales_count:,} → {len(sales_df):,}\")\n",
    "\n",
    "# CLEANING STEP 3: Add Business-Relevant Columns\n",
    "print(\"\\nSTEP 3: Adding Business Columns\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Add time-based features to sales\n",
    "sales_df['year'] = sales_df['date'].dt.year\n",
    "sales_df['month'] = sales_df['date'].dt.month\n",
    "sales_df['day_of_week'] = sales_df['date'].dt.day_name()\n",
    "sales_df['is_weekend'] = sales_df['date'].dt.weekday.isin([5, 6]).astype(int)\n",
    "\n",
    "# Add season\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "sales_df['season'] = sales_df['month'].apply(get_season)\n",
    "\n",
    "# Add location details to sales\n",
    "location_details = locations_df[['location_id', 'city', 'location_type']].copy()\n",
    "sales_df = sales_df.merge(location_details, on='location_id', how='left')\n",
    "\n",
    "print(\"Added time features and location details to sales data\")\n",
    "\n",
    "# CLEANING STEP 4: Create Summary Tables\n",
    "print(\"\\nSTEP 4: Creating Summary Tables\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Daily sales summary by location\n",
    "daily_summary = sales_df.groupby(['date', 'location_id', 'city', 'location_type']).agg({\n",
    "    'revenue': 'sum',\n",
    "    'profit': 'sum',\n",
    "    'quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "daily_summary = daily_summary.rename(columns={\n",
    "    'revenue': 'daily_revenue',\n",
    "    'profit': 'daily_profit', \n",
    "    'quantity': 'daily_items_sold'\n",
    "})\n",
    "\n",
    "print(f\"Created daily summary: {len(daily_summary):,} records\")\n",
    "\n",
    "# Monthly summary by location\n",
    "monthly_summary = sales_df.groupby(['year', 'month', 'location_id', 'city', 'location_type']).agg({\n",
    "    'revenue': 'sum',\n",
    "    'profit': 'sum',\n",
    "    'quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_summary = monthly_summary.rename(columns={\n",
    "    'revenue': 'monthly_revenue',\n",
    "    'profit': 'monthly_profit',\n",
    "    'quantity': 'monthly_items_sold'\n",
    "})\n",
    "\n",
    "# Add location operating costs\n",
    "location_costs = locations_df[['location_id', 'monthly_rent']].copy()\n",
    "monthly_summary = monthly_summary.merge(location_costs, on='location_id', how='left')\n",
    "monthly_summary['net_profit'] = monthly_summary['monthly_profit'] - monthly_summary['monthly_rent']\n",
    "\n",
    "print(f\"Created monthly summary: {len(monthly_summary):,} records\")\n",
    "\n",
    "# CLEANING STEP 5: Weather Data Enhancement\n",
    "print(\"\\nSTEP 5: Enhancing Weather Data\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Add temperature categories\n",
    "def categorize_temperature(temp):\n",
    "    if temp < 40:\n",
    "        return 'Cold'\n",
    "    elif temp < 70:\n",
    "        return 'Mild'\n",
    "    else:\n",
    "        return 'Hot'\n",
    "\n",
    "weather_df['temp_category'] = weather_df['temperature'].apply(categorize_temperature)\n",
    "\n",
    "# Add weather impact score (business metric)\n",
    "def weather_impact_score(row):\n",
    "    score = 1.0  # neutral\n",
    "    \n",
    "    # Temperature impact\n",
    "    if row['temp_category'] == 'Mild':\n",
    "        score += 0.1  # Mild weather boosts sales\n",
    "    elif row['temp_category'] == 'Cold':\n",
    "        score -= 0.05\n",
    "    \n",
    "    # Rain impact\n",
    "    if row['is_rainy']:\n",
    "        score -= 0.15  # Rain hurts sales\n",
    "    \n",
    "    return round(score, 2)\n",
    "\n",
    "weather_df['weather_impact_score'] = weather_df.apply(weather_impact_score, axis=1)\n",
    "\n",
    "print(\"Added temperature categories and weather impact scores\")\n",
    "\n",
    "# CLEANING STEP 6: Save Cleaned Data\n",
    "print(\"\\nSTEP 6: Saving Cleaned Data\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Save cleaned datasets\n",
    "locations_df.to_csv('locations_cleaned.csv', index=False)\n",
    "menu_df.to_csv('menu_items_cleaned.csv', index=False)\n",
    "sales_df.to_csv('sales_data_cleaned.csv', index=False)\n",
    "weather_df.to_csv('weather_data_cleaned.csv', index=False)\n",
    "\n",
    "# Save summary tables\n",
    "daily_summary.to_csv('daily_sales_summary.csv', index=False)\n",
    "monthly_summary.to_csv('monthly_sales_summary.csv', index=False)\n",
    "\n",
    "print(\"All cleaned datasets saved!\")\n",
    "\n",
    "# FINAL DATA QUALITY REPORT\n",
    "print(\"\\nFINAL DATA QUALITY REPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Locations: {len(locations_df)} restaurants across {locations_df['city'].nunique()} cities\")\n",
    "print(f\"Menu: {len(menu_df)} items, all with positive margins\")\n",
    "print(f\"Sales: {len(sales_df):,} clean transactions\")\n",
    "print(f\"Weather: {len(weather_df):,} daily records with business impact scores\")\n",
    "print(f\"Daily Summary: {len(daily_summary):,} location-day combinations\")\n",
    "print(f\"Monthly Summary: {len(monthly_summary):,} location-month combinations\")\n",
    "\n",
    "# Data quality metrics\n",
    "print(f\"\\nData Quality Metrics:\")\n",
    "print(f\"  Missing values: 0%\")\n",
    "print(f\"  Date range: {sales_df['date'].min().strftime('%Y-%m-%d')} to {sales_df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"  Revenue range: ${sales_df['revenue'].min():.2f} - ${sales_df['revenue'].max():.2f}\")\n",
    "print(f\"  All business relationships maintained\")\n",
    "\n",
    "print(\"Data is clean and ready for SQL analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a86473-2f87-40a5-8e7e-403556d7e99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
