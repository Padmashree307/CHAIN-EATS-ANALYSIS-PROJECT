{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828cf081-a367-449f-9ec3-1928942ff07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ChainEats Analytics Dataset...\n",
      "==================================================\n",
      "Generating 50 restaurant locations...\n",
      "Created 50 locations across 5 cities\n",
      "Creating menu items...\n",
      "Created 20 menu items across 5 categories\n",
      "Generating 2 years of daily sales data...\n",
      "Generated 13,605,203 sales transactions\n",
      "Adding weather data...\n",
      "Generated weather data for 730 days across 5 cities\n",
      "Saving datasets...\n",
      "All datasets saved!\n",
      "\n",
      "Dataset Summary:\n",
      "Locations: 50 records\n",
      "Menu Items: 20 records\n",
      "Sales Transactions: 13,605,203 records\n",
      "Weather Records: 3,650 records\n",
      "\n",
      "Quick Data Preview:\n",
      "\n",
      "1. Top 5 Locations by Type:\n",
      "location_type\n",
      "Mall          13\n",
      "Street        13\n",
      "Standalone    12\n",
      "Airport        6\n",
      "Food Court     6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2. Sales by Category (sample):\n",
      "category\n",
      "Pizza        6.374138e+07\n",
      "Burgers      4.672071e+07\n",
      "Salads       4.668045e+07\n",
      "Desserts     2.830575e+07\n",
      "Beverages    1.470787e+07\n",
      "Name: revenue, dtype: float64\n",
      "\n",
      "3. Date range: 2022-01-01 00:00:00 to 2023-12-31 00:00:00\n",
      "\n",
      "Day 1 Complete! Ready for data cleaning\n"
     ]
    }
   ],
   "source": [
    "# ChainEats Analytics - Day 1: Data Generation (OPTIMIZED)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Creating ChainEats Analytics Dataset...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Step 1: Create Location Master Data\n",
    "print(\"Generating 50 restaurant locations...\")\n",
    "\n",
    "cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Miami']\n",
    "location_types = ['Mall', 'Street', 'Food Court', 'Airport', 'Standalone']\n",
    "\n",
    "locations_data = []\n",
    "for i in range(1, 51):\n",
    "    city = random.choice(cities)\n",
    "    location_type = random.choice(location_types)\n",
    "    \n",
    "    # Create realistic rent and foot traffic based on location type\n",
    "    base_rent = {'Mall': 8000, 'Street': 6000, 'Food Court': 4000, 'Airport': 12000, 'Standalone': 5000}\n",
    "    base_traffic = {'Mall': 500, 'Street': 300, 'Food Court': 800, 'Airport': 1200, 'Standalone': 200}\n",
    "    \n",
    "    locations_data.append({\n",
    "        'location_id': f'LOC_{i:03d}',\n",
    "        'city': city,\n",
    "        'location_type': location_type,\n",
    "        'monthly_rent': base_rent[location_type] + np.random.randint(-1000, 1000),\n",
    "        'avg_daily_foottraffic': base_traffic[location_type] + np.random.randint(-100, 100),\n",
    "        'opening_date': datetime(2022, 1, 1) + timedelta(days=np.random.randint(0, 365)),\n",
    "        'size_sqft': np.random.randint(800, 2000)\n",
    "    })\n",
    "\n",
    "locations_df = pd.DataFrame(locations_data)\n",
    "print(f\"Created {len(locations_df)} locations across {len(cities)} cities\")\n",
    "\n",
    "# Step 2: Create Menu Items\n",
    "print(\"Creating menu items...\")\n",
    "\n",
    "menu_categories = ['Burgers', 'Pizza', 'Salads', 'Beverages', 'Desserts']\n",
    "items_per_category = {\n",
    "    'Burgers': ['Classic Burger', 'Cheese Burger', 'Chicken Burger', 'Veggie Burger'],\n",
    "    'Pizza': ['Margherita', 'Pepperoni', 'Supreme', 'Veggie Pizza'],\n",
    "    'Salads': ['Caesar Salad', 'Greek Salad', 'Chicken Salad', 'Garden Salad'],\n",
    "    'Beverages': ['Coca Cola', 'Orange Juice', 'Water', 'Coffee'],\n",
    "    'Desserts': ['Ice Cream', 'Chocolate Cake', 'Apple Pie', 'Cookies']\n",
    "}\n",
    "\n",
    "menu_data = []\n",
    "item_id = 1\n",
    "for category, items in items_per_category.items():\n",
    "    for item in items:\n",
    "        # Realistic pricing based on category\n",
    "        base_prices = {'Burgers': 12, 'Pizza': 15, 'Salads': 10, 'Beverages': 3, 'Desserts': 6}\n",
    "        base_costs = {'Burgers': 5, 'Pizza': 6, 'Salads': 4, 'Beverages': 1, 'Desserts': 2}\n",
    "        \n",
    "        menu_data.append({\n",
    "            'item_id': f'ITEM_{item_id:03d}',\n",
    "            'item_name': item,\n",
    "            'category': category,\n",
    "            'price': base_prices[category] + np.random.uniform(-2, 3),\n",
    "            'cost': base_costs[category] + np.random.uniform(-1, 1)\n",
    "        })\n",
    "        item_id += 1\n",
    "\n",
    "menu_df = pd.DataFrame(menu_data)\n",
    "menu_df['profit_margin'] = menu_df['price'] - menu_df['cost']\n",
    "print(f\"Created {len(menu_df)} menu items across {len(menu_categories)} categories\")\n",
    "\n",
    "# Step 3: Generate Daily Sales Data (2 years) - OPTIMIZED\n",
    "print(\"Generating 2 years of daily sales data...\")\n",
    "\n",
    "start_date = datetime(2022, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "# Pre-compute menu item selections for efficiency\n",
    "menu_items = menu_df[['item_id', 'item_name', 'category', 'price', 'cost']].values\n",
    "menu_weights = np.ones(len(menu_df))  # Equal probability for all items\n",
    "menu_indices = np.arange(len(menu_df))\n",
    "\n",
    "# Create some locations that are consistently better/worse performers\n",
    "high_performers = random.sample(locations_df['location_id'].tolist(), 10)\n",
    "low_performers = random.sample(locations_df['location_id'].tolist(), 10)\n",
    "\n",
    "# Pre-compute seasonal and weekday multipliers for all dates\n",
    "seasonal_multipliers = []\n",
    "weekday_multipliers = []\n",
    "\n",
    "for current_date in date_range:\n",
    "    # Seasonal multiplier\n",
    "    month = current_date.month\n",
    "    seasonal_mult = 1.0\n",
    "    if month in [6, 7, 8]:  # Summer\n",
    "        seasonal_mult = 1.2\n",
    "    elif month in [11, 12]:  # Holiday season\n",
    "        seasonal_mult = 1.3\n",
    "    seasonal_multipliers.append(seasonal_mult)\n",
    "    \n",
    "    # Weekend multiplier\n",
    "    weekday_mult = 1.4 if current_date.weekday() in [5, 6] else 1.0\n",
    "    weekday_multipliers.append(weekday_mult)\n",
    "\n",
    "# Generate all sales data in batches\n",
    "sales_data = []\n",
    "batch_size = 10000  # Process in batches to manage memory\n",
    "\n",
    "total_transactions = 0\n",
    "for date_idx, current_date in enumerate(date_range):\n",
    "    seasonal_mult = seasonal_multipliers[date_idx]\n",
    "    weekday_mult = weekday_multipliers[date_idx]\n",
    "    \n",
    "    for _, location in locations_df.iterrows():\n",
    "        # Base sales influenced by location characteristics\n",
    "        base_sales = location['avg_daily_foottraffic'] * 0.3  # 30% conversion rate\n",
    "        \n",
    "        # Performance tier adjustment\n",
    "        if location['location_id'] in high_performers:\n",
    "            base_sales *= 1.3\n",
    "        elif location['location_id'] in low_performers:\n",
    "            base_sales *= 0.7\n",
    "        \n",
    "        # Apply multipliers\n",
    "        daily_customers = int(base_sales * seasonal_mult * weekday_mult * np.random.uniform(0.7, 1.3))\n",
    "        \n",
    "        if daily_customers > 0:\n",
    "            # Generate all item selections at once for this location-date\n",
    "            total_items = 0\n",
    "            for customer in range(daily_customers):\n",
    "                items_ordered = np.random.randint(1, 4)\n",
    "                total_items += items_ordered\n",
    "            \n",
    "            if total_items > 0:\n",
    "                # Vectorized item selection\n",
    "                selected_menu_indices = np.random.choice(\n",
    "                    menu_indices, \n",
    "                    size=total_items, \n",
    "                    p=menu_weights/menu_weights.sum()\n",
    "                )\n",
    "                \n",
    "                quantities = np.random.randint(1, 3, size=total_items)\n",
    "                \n",
    "                # Build batch of sales records\n",
    "                for i, menu_idx in enumerate(selected_menu_indices):\n",
    "                    item_data = menu_items[menu_idx]\n",
    "                    quantity = quantities[i]\n",
    "                    \n",
    "                    sales_data.append({\n",
    "                        'date': current_date,\n",
    "                        'location_id': location['location_id'],\n",
    "                        'item_id': item_data[0],\n",
    "                        'item_name': item_data[1],\n",
    "                        'category': item_data[2],\n",
    "                        'quantity': quantity,\n",
    "                        'price': item_data[3],\n",
    "                        'cost': item_data[4]\n",
    "                    })\n",
    "                    \n",
    "                    total_transactions += 1\n",
    "                    \n",
    "                    # Process in batches to manage memory\n",
    "                    if len(sales_data) >= batch_size:\n",
    "                        if 'sales_df_parts' not in locals():\n",
    "                            sales_df_parts = []\n",
    "                        \n",
    "                        batch_df = pd.DataFrame(sales_data)\n",
    "                        batch_df['revenue'] = batch_df['quantity'] * batch_df['price']\n",
    "                        batch_df['total_cost'] = batch_df['quantity'] * batch_df['cost']\n",
    "                        batch_df['profit'] = batch_df['revenue'] - batch_df['total_cost']\n",
    "                        \n",
    "                        sales_df_parts.append(batch_df)\n",
    "                        sales_data = []  # Clear for next batch\n",
    "\n",
    "# Process final batch\n",
    "if sales_data:\n",
    "    if 'sales_df_parts' not in locals():\n",
    "        sales_df_parts = []\n",
    "    \n",
    "    batch_df = pd.DataFrame(sales_data)\n",
    "    batch_df['revenue'] = batch_df['quantity'] * batch_df['price']\n",
    "    batch_df['total_cost'] = batch_df['quantity'] * batch_df['cost']\n",
    "    batch_df['profit'] = batch_df['revenue'] - batch_df['total_cost']\n",
    "    \n",
    "    sales_df_parts.append(batch_df)\n",
    "\n",
    "# Combine all batches\n",
    "if 'sales_df_parts' in locals():\n",
    "    sales_df = pd.concat(sales_df_parts, ignore_index=True)\n",
    "else:\n",
    "    sales_df = pd.DataFrame(columns=['date', 'location_id', 'item_id', 'item_name', 'category', 'quantity', 'price', 'cost', 'revenue', 'total_cost', 'profit'])\n",
    "\n",
    "print(f\"Generated {len(sales_df):,} sales transactions\")\n",
    "\n",
    "# Step 4: Add Weather Data (simplified) - OPTIMIZED\n",
    "print(\"Adding weather data...\")\n",
    "\n",
    "# Pre-generate all weather data at once\n",
    "n_weather_records = len(date_range) * len(cities)\n",
    "weather_dates = np.repeat(date_range, len(cities))\n",
    "weather_cities = np.tile(cities, len(date_range))\n",
    "\n",
    "# Vectorized temperature generation based on month\n",
    "months = np.array([date.month for date in weather_dates])\n",
    "\n",
    "# Create temperature based on season\n",
    "temperatures = np.zeros(len(months))\n",
    "winter_mask = np.isin(months, [12, 1, 2])\n",
    "spring_mask = np.isin(months, [3, 4, 5])\n",
    "summer_mask = np.isin(months, [6, 7, 8])\n",
    "fall_mask = ~(winter_mask | spring_mask | summer_mask)\n",
    "\n",
    "temperatures[winter_mask] = np.random.normal(35, 10, np.sum(winter_mask))\n",
    "temperatures[spring_mask] = np.random.normal(60, 10, np.sum(spring_mask))\n",
    "temperatures[summer_mask] = np.random.normal(80, 8, np.sum(summer_mask))\n",
    "temperatures[fall_mask] = np.random.normal(65, 10, np.sum(fall_mask))\n",
    "\n",
    "# Apply realistic bounds\n",
    "temperatures = np.clip(temperatures, 20, 100)\n",
    "\n",
    "# Generate precipitation and rain data\n",
    "precipitation = np.random.exponential(0.1, n_weather_records)\n",
    "is_rainy = np.random.choice([0, 1], size=n_weather_records, p=[0.8, 0.2])\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'date': weather_dates,\n",
    "    'city': weather_cities,\n",
    "    'temperature': temperatures,\n",
    "    'precipitation': precipitation,\n",
    "    'is_rainy': is_rainy\n",
    "})\n",
    "\n",
    "print(f\"Generated weather data for {len(date_range)} days across {len(cities)} cities\")\n",
    "\n",
    "# Step 5: Save all datasets\n",
    "print(\"Saving datasets...\")\n",
    "\n",
    "locations_df.to_csv('locations.csv', index=False)\n",
    "menu_df.to_csv('menu_items.csv', index=False)\n",
    "sales_df.to_csv('sales_data.csv', index=False)\n",
    "weather_df.to_csv('weather_data.csv', index=False)\n",
    "\n",
    "print(\"All datasets saved!\")\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(f\"Locations: {len(locations_df):,} records\")\n",
    "print(f\"Menu Items: {len(menu_df):,} records\") \n",
    "print(f\"Sales Transactions: {len(sales_df):,} records\")\n",
    "print(f\"Weather Records: {len(weather_df):,} records\")\n",
    "\n",
    "# Quick preview\n",
    "print(\"\\nQuick Data Preview:\")\n",
    "print(\"\\n1. Top 5 Locations by Type:\")\n",
    "print(locations_df['location_type'].value_counts().head())\n",
    "\n",
    "print(\"\\n2. Sales by Category (sample):\")\n",
    "if len(sales_df) > 0:\n",
    "    category_sales = sales_df.groupby('category')['revenue'].sum().sort_values(ascending=False)\n",
    "    print(category_sales)\n",
    "\n",
    "print(\"\\n3. Date range:\", sales_df['date'].min(), \"to\", sales_df['date'].max())\n",
    "\n",
    "print(\"\\nDay 1 Complete! Ready for data cleaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac31401-adab-4e67-875e-b95101248b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
